<!--
  %\VignetteEngine{knitr}
  %\VignetteIndexEntry{hypothetical example}
  %\VignetteDepends{categoryComparePaperRev, ggplot2, ALL, GO.db, hgu95av.db, hgu133plus2.db, limma}
-->
  
# Hypothetical Example
  
To demonstrate the utility of the general `categoryCompare` approach, we will construct an artificial data set based on the Gene Ontology. We will attempt to demonstrate that differences in the **set** or **list** based comparisons are also dependent on the number of items annotated to a particular term.

## Definitions

**Set** based: calculations performed independently on each *set* of features, and then the results are combined.

**List** based: calculations performed on the intersected *list* of two sets of features.

## GO Terms

```{r nGO}
nGO <- 20
```

We will make use of three sets of `r nGO` GO terms from *H. sapiens*. For each set, we want differing numbers of genes annotated to them.

### Num Annotations Dist

Let's first look at the distribution of number of genes annotated to the GO terms in **biological process**

```{r goAnnotations}
library(org.Hs.eg.db)
library(GO.db)
library(ccPaperRev)
hsGO <- as.list(org.Hs.egGO2ALLEGS)

goOntology <- Ontology(names(hsGO))
goBP <- names(goOntology)[goOntology == "BP"]
hsGO <- hsGO[goBP]
hsGO <- lapply(hsGO, unique)
universeGenes <- unique(unlist(hsGO))
```

```{r goCountDist}
library(ggplot2)
hsGO_count <- sapply(hsGO, length)
hsGO_count <- data.frame(count=hsGO_count)
ggplot(hsGO_count, aes(x=count)) + geom_bar(binwidth=10) + xlim(0, 2000) + ylim(0, 500)
```

### Set up groups

```{r defineMin}
minGO <- 10
```

Let us define a minimum number of genes that need to be annotated to a GO term (`r minGO`), and then divide the GO terms into groups that we can subsequently take random samples from.

```{r defineGroupLimits}
grpLow <- c(10, 100)
grpMed <- c(250, 500)
grpHi <- c(500, 1500)
```

```{r sampleGroups}
set.seed(271113) # for reproducibility
nGO <- c(50, 30, 20)
names(nGO) <- c("low", "med", "hi")

GO_low <- limitedRandomSample(hsGO_count, grpLow, nGO["low"])
GO_med <- limitedRandomSample(hsGO_count, grpMed, nGO["med"])
GO_hi <- limitedRandomSample(hsGO_count, grpHi, nGO["hi"])
```

### Examine Gene-GO Distribution for Real Data

Before we go and generate our samples, we should actually process some real experimental data and examine the fraction of annotated genes in the experiment compared to the total number of genes annotated. We will use the [`ALL`][http://master.bioconductor.org/packages/release/data/experiment/html/ALL.html] data set from `Bioconductor` and a [paired lung cancer dataset][http://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE18842] available from GEO (available as part of this package).

#### ALL

The `ALL` data set has two classes of tumor, **B** and **T**-cell lymphoblastoma. We will do a simple differential expression between the two cell types.

```{r deALL}
library(ALL)
library(limma)
data(ALL)

grpALL <- factor(strtrim(pData(ALL)$BT, 1))
designALL <- model.matrix(~0+grpALL)
colnames(designALL) <- c("B", "T")
fitALL <- lmFit(ALL, designALL)
contMatrixALL <- makeContrasts(BvT=B-T, levels=designALL)
fitALL2 <- contrasts.fit(fitALL, contMatrixALL)
fitALL2 <- eBayes(fitALL2)
deALL <- rownames(topTable(fitALL2, adjust="BH", p.value=0.05, number=Inf))
```

Now for all the GO terms that map to the probes in the `ALL` differentially expressed genes, how does the proportion of differentially expressed genes change as a function of the number of genes annotated to the GO term?

```{r goDistALL}
library(hgu95av2.db)
ALLgo <- as.list(hgu95av2GO2ALLPROBES)
ALL_sizeFrac <- trimGOFrac(ALLgo, deALL)
ggplot(ALL_sizeFrac, aes(x=size, y=frac)) + geom_point() + xlim(0, 1500)
```


#### Lung Cancer

The lung cancer data is a paired sample design from GEO.

```{r deLung}
data(lung)
sampleStat <- strsplit2(pData(lung)$title, " ")

notNP <- grep("^NP", sampleStat[,2], invert=T)
lung <- lung[, notNP]
sampleStat <- sampleStat[notNP,]

sampleID <- factor(sampleStat[,2])
cancerID <- factor(sampleStat[,1])

lungDesign <- model.matrix(~sampleID+cancerID)
fitLung <- lmFit(lung, lungDesign)
fitLung <- eBayes(fitLung)
deLung <- rownames(topTable(fitLung, coef="cancerIDTumor", number=2000, adjust.method="BY", p.value=0.00001))
```

```{r goDistLung}
library(hgu133plus2.db)
lung2go <- as.list(hgu133plus2GO2ALLPROBES)
lung_sizeFrac <- trimGOFrac(lung2go, deLung)
lung_sizeFrac$genelist <- "lung"
ggplot(lung_sizeFrac, aes(x=size, y=frac)) + geom_point() + xlim(0, 1500)
```



### Get Genes

Now, for all of these we need to generate **two** samples of genes from them to comprise our **differentially expressed** (DE) sets from the genome, representing two different expression experiments.

How do we select these two sets of genes?

* define the maximum number of diff genes for the set
* Randomly sort the GO terms
* For each GO term in turn (i.e. iterating over the GO terms):
  * take a random fraction of genes for that GO term (sampling from an exponentially decaying distribution of possibilites), adding the requisite number of genes
  * If all the genes for a GO term get taken, remove that GO term from future consideration
* Continue iterating through until the total number of genes is reached

What we expect from this is that in both datasets, the GO terms with lower numbers of genes annotated will have large fractions of their annotations present, while GO terms with more and more genes will have lower fractions, and there will be less overlap between the two datasets.

These expectations should be checked.



```{r generateSamples}
useGO <- c(GO_low, GO_med, GO_hi)
goList <- list(low=GO_low, med=GO_med, hi=GO_hi)
nGene <- 1000
sample1_org <- sampleTerms(useGO, hsGO, 1000, 4)[1:nGene]
sample2_org <- sampleTerms(useGO, hsGO, 1000, 4)[1:nGene]
```

### Checking our expectations about the fractions of GO terms.

```{r checkFractions}
goFractions <- calcFraction(hsGO[useGO], list(sample1=sample1_org, sample2=sample2_org))
ggplot(goFractions, aes(x=size, y=frac, color=genelist)) + geom_point()
```

Lets actually compare this to the distribution of fractions *vs* sizes from the experimental data sets. Because those used **all** the GO terms, we will redo them with **all** GO terms as well, not just those from our sample.

```{r compareFracs}
sampleGOFracs <- calcFraction(hsGO, list(sample1=sample1_org, sample2=sample2_org))
ALL_sizeFrac$genelist <- "all"
ALL_tmp <- rbind(ALL_sizeFrac, lung_sizeFrac, sampleGOFracs[,c("frac", "genelist", "size")])
ggplot(ALL_tmp, aes(x=size, y=frac)) + geom_point() + xlim(0, 1500) + facet_grid(genelist ~ .)
```


```{r cleanupData}
keepItems <- c("goFractions", "sample1_org", "sample2_org", "hsGO", "useGO", "GO_hi", "GO_low", "GO_med", "grpHi", "grpLow", "grpMed", "minGO", "nGO", "nGene", "universeGenes")
allItems <- ls()
delItems <- allItems[!(allItems %in% keepItems)]
rm(list=delItems)
```


### Do calculations

For each `geneList`, we will do the GO enrichment calculations, and then get the results. We also do the intersection of all the `geneList`'s, and do the calculations again.

```{r runCalcs}
samples_noNoise <- list(sample1 = sample1_org, sample2 = sample2_org)
go_noNoise <- hyperGOMultiEnrichment(samples_noNoise, universe=universeGenes)
```

Now get the p-values out (`-1 * log10(pvalue)`). For each of our test GO terms, we take the minimum p-value from the results of the **set** calculations, and also the values from the **list** calculations.

```{r noNoisePvalues}
noNoise_results <- pvaluesMultiEnrich(c("sample1", "sample2"), useGO, go_noNoise)

noNoise_pvalues <- pvalueDiffSig(noNoise_results$values, pCutoff=0.05, log=TRUE)
```

Finally, lets add in our values of the fraction, total genes, and the class (**low**, **med**, **hi**) so we can do some fancy plotting stuff with it.

```{r noNoiseAddInfo}
sizeClass <- c(rep("low", nGO["low"]), rep("med", nGO["med"]), rep("hi", nGO["hi"]))
names(sizeClass) <- useGO
noNoise_pvalues$sizeClass <- sizeClass
noNoise_pvalues$size <- goFractions[1:length(sizeClass),4]
noNoise_pvalues$frac <- goFractions$frac[1:length(sizeClass)]
```

Now we will plot the difference in log-p-values (where we have **set** - **list**), so that positive values imply that **set** had lower p-values than **list**, based on the *fraction* of genes annotated.

```{r noNoisePlotStuff}
noNoise_pvalues$sizeClass <- factor(noNoise_pvalues$sizeClass, levels=c("low", "med", "hi"), ordered=TRUE)
ggplot(noNoise_pvalues, aes(x=frac, y=diff, color=sigState)) + geom_point() + facet_grid(. ~ sizeClass, scales="free_x")
ggplot(noNoise_pvalues, aes(x=sizeClass, y=diff)) + geom_boxplot() + geom_point()
```

We can see that it appears in general that **set** has better p-values than **list**, especially in the *med* and *hi* groups. Also, both methods get pretty much the same GO terms as significant. 

How many of the GO terms have better p-values in **set** compared to **list**?

```{r noNoiseBetterPVals}
tapply(noNoise_pvalues$diff, noNoise_pvalues$sizeClass, function(x){sum(x > 0)})
```

What is the average difference among each group?

```{r noNoiseBetterMean}
tapply(noNoise_pvalues$diff, noNoise_pvalues$sizeClass, mean)
```

So ideally, the mean of the full set of differences, combined with how many pass in each case, should adequately quantify how well each of the methods is doing. 

## Noise

In addition to the genes that are annotated to the GO terms of interest, we will also add in genes that have no relation to the GO terms under consideration, these would be considered **noise** genes. To make the model simple, we will have the **same** genes as noise in **both** samples.

```{r noiseGenes}
nNoise <- 500
gene2HsGO <- reverseSplit(hsGO)
not_useGO <- sapply(gene2HsGO, function(x){
  sum(x %in% useGO) == 0
})
noiseGenes <- names(not_useGO)[not_useGO]
noiseGenes <- sample(noiseGenes, nNoise)

# check that we did this right, the fraction should not change after adding noise genes
sample1 <- c(sample1_org, noiseGenes)
sample2 <- c(sample2_org, noiseGenes)

samplesNoise <- list(sample1=sample1, sample2=sample2)

goFracNoise <- calcFraction(hsGO[useGO], samplesNoise)
plot(goFracNoise$frac, goFractions$frac)
```


```{r noisyEnrichment}
go_noise <- hyperGOMultiEnrichment(samplesNoise, universeGenes)
```

```{r noisePvalues}
noise_results <- pvaluesMultiEnrich(c("sample1", "sample2"), useGO, go_noise)

noise_pvalues <- pvalueDiffSig(noise_results$values, pCutoff=0.05, log=TRUE)

noise_pvalues$sizeClass <- sizeClass
noise_pvalues$size <- goFracNoise[1:length(sizeClass),4]
noise_pvalues$frac <- goFracNoise$frac[1:length(sizeClass)]
```

```{r plotSummarizeNoise}
noise_pvalues$sizeClass <- factor(noise_pvalues$sizeClass, c("low", "med", "hi"), ordered=TRUE)
ggplot(noise_pvalues, aes(x=frac, y=diff, color=sigState)) + geom_point() + facet_grid(. ~ sizeClass, scales="free_x")
```

```{r summarizeCountsNoise}
tapply(noise_pvalues$diff, noise_pvalues$sizeClass, function(x){sum(x > 0)})
tapply(noise_pvalues$diff, noise_pvalues$sizeClass, mean)
```

Although using gene lists that were perfect (i.e. no noise) everything in the **list** method was pretty much still significant, on average **sets** gave much better p-values. However, as we add noise to the system in the form of genes that are not annotated to our test GO terms, more terms are significant only in the **sets** method (i.e. show up in **both** sets). 

## Check Consistency

To make sure that the results are consistent, we will do several iterations of the above calculations.

* Generate 100 different sets of GO samples, and run calculations again.
* For 10 subsets of these, generate 100 different pairs of sample genes, and run calculations.

This should be done for both the **noNoise** and **noise** examples.

### Gene Sample Level Consistency

```{r geneSamples, eval=FALSE}
nTimes <- 100
nGene <- 1000

testSamples <- lapply(seq(1, nTimes), function(x){
  list(s1 = sampleTerms(useGO, hsGO, 1000, 4)[1:nGene],
       s2 = sampleTerms(useGO, hsGO, 1000, 4)[1:nGene])
})

save(useGO, testSamples, universeGenes, sizeClass, file="inst/data/100GeneSamples.RData")
```

```{r runSamples, eval=FALSE}
library(snowfall)
# load("inst/data/100GeneSamples.RData")
testFun <- function(x){
  sRes <- hyperGOMultiEnrichment(x, universe=universeGenes)

  sP_res <- pvaluesMultiEnrich(c("s1", "s2"), useGO, sRes)
  sP <- pvalueDiffSig(sP_res$values, pCutoff=0.05, log=TRUE)
  sP$class <- sizeClass
  return(list(results = sP_res, values = sP))
}
sfInit(parallel=TRUE, cpus=10)
sfExport("sizeClass", "universeGenes", "useGO")
sfLibrary(ccPaperRev)
sfLibrary(GO.db)
sfLibrary(org.Hs.eg.db)
testRes <- sfLapply(testSamples, testFun)
sfStop()
save(testRes, file="inst/data/100GeneResults.RData")
```

```{r noiseSamples, eval=FALSE}
nTimes <- 100
nGenes <- 1000

nNoise <- 500
gene2HsGO <- reverseSplit(hsGO)
not_useGO <- sapply(gene2HsGO, function(x){
  sum(x %in% useGO) == 0
})
possibleNoise <- names(not_useGO)[not_useGO]

noiseSamples <- lapply(seq(1, nTimes), function(x){
  noiseGenes <- sample(possibleNoise, nNoise)
  s1 <- c(sampleTerms(useGO, hsGO, 1000, 4)[1:nGene], noiseGenes)
  s2 <- c(sampleTerms(useGO, hsGO, 1000, 4)[1:nGene], noiseGenes)
  return(list(s1 = s1, s2 = s2))
})

save(useGO, noiseSamples, universeGenes, sizeClass, file="inst/data/100NoiseSamples.RData")
```

```{r noiseResults, eval=FALSE}
sfInit(parallel=TRUE, cpus=10)
sfExport("sizeClass", "universeGenes", "useGO")
sfLibrary(ccPaperRev)
sfLibrary(GO.db)
sfLibrary(org.Hs.eg.db)
noiseRes <- sfLapply(noiseSamples, testFun)
sfStop()
save(noiseRes, file="inst/data/100NoiseResults.RData")
```



### Errors from 100 Samples of the initial set of GO terms

For each of the GO terms, we want to calculate the mean, standard deviation, and then a 95% confidence interval to represent graphically.

```{r noNoiseStats}
testStats_noNoise <- sameGOStats(testRes)
testStats_noNoise$class <- sizeClass
testStats_noNoise$frac <- goFracNoise$frac[1:length(sizeClass)]
testStats_noNoise$class <- factor(testStats_noNoise$class, levels=c("low", "med", "hi"), ordered=TRUE)
ggplot(testStats_noNoise, aes(x=frac, y=mean, ymax=max, ymin=min)) + geom_point() + geom_errorbar() + facet_grid(. ~ class, scales="free_x")
```

```{r noiseStats}
testStats_noise <- sameGOStats(noiseRes)
testStats_noise$class <- sizeClass
testStats_noise$frac <- goFracNoise$frac[1:length(sizeClass)]
testStats_noise$class <- factor(testStats_noise$class, levels=c("low", "med", "hi"), ordered=TRUE)
ggplot(testStats_noise, aes(x=frac, y=mean, ymax=max, ymin=min)) + geom_point() + geom_errorbar() + facet_grid(. ~ class, scales="free_x")
```


## GO Samples

OK, the error bars are not too bad. How about sampling multiple sets of GO terms. This is slightly complicated by the fact that we will not get exactly the same values for the fraction, so we will bin the GO terms by the fraction of annotated genes first, and then calculate the statistics.


```{r genSamples}
goLimits <- list(low = c(10, 100), med = c(250, 500), hi = c(500, 1500))

nSample <- 100

sfInit(parallel=TRUE, cpus=10)
sfLibrary(ccPaperRev)
sfExport("hsGO", "nGO", "goLimits")

testGOSample <- sfLapply(seq(1, nSample), function(x){
  t1 <- goSample(hsGO, nGO, goLimits, nSample=2, nGene=1000, nNoise=500)
  return(t1)
})

sfStop()
save(testGOSample, file="inst/data/100GOSamples.RData")
```

Running those samples:

```{r runGOSamples}
runGOSamples <- function(x){
  cleanSample <- x$geneSample
  cleanRes <- hyperGOMultiEnrichment(cleanSample, universe=universeGenes)
  
  cleanP <- pvaluesMultiEnrich(names(cleanSample), x$goData$id, cleanRes)
  cleanP_dif <- pvalueDiffSig(cleanP$values, pCutoff=0.05, log=TRUE)
  cleanP_dif <- cbind(cleanP_dif, x$goData)
  
  noiseSample <- lapply(names(cleanSample), function(inSample){
    c(x$geneSample[[inSample]], x$noiseSample[[inSample]])
  })
  names(noiseSample) <- names(cleanSample)
  noiseRes <- hyperGOMultiEnrichment(noiseSample, universe=universeGenes)
  noiseP <- pvaluesMultiEnrich(names(cleanSample), x$goData$id, noiseRes)
  noiseP_dif <- pvalueDiffSig(noiseP$values, pCutoff=0.05, log=TRUE)
  noiseP_dif <- cbind(noiseP_dif, x$goData)
  return(list(clean = cleanP_dif, noise = noiseP_dif))
}

library(snowfall)
sfInit(parallel=TRUE, cpus=10)
sfLibrary(ccPaperRev)
sfLibrary(org.Hs.eg.db)
sfLibrary(GO.db)
sfExport("universeGenes")

testGORes <- sfLapply(testGOSample, runGOSamples)
sfStop()
save(testGORes, file="inst/data/100GOResults.RData")
```

```{r lookDiffs}
load("inst/data/100GOResults.RData")

grab_noNoise <- function(x){
  x$clean[,c("diff", "class", "frac")]
}

go_noNoise <- lapply(testGORes, grab_noNoise)
go_noNoise <- do.call(rbind, go_noNoise)
go_noNoise$class <- factor(go_noNoise$class, levels=c("low", "med", "hi"), ordered=TRUE)
ggplot(go_noNoise, aes(x = frac, y = diff)) + geom_point() + facet_grid(. ~ class, scales="free_x")

grab_noise <- function(x){
  x$noise[, c("diff", "class", "frac")]
}
go_noise <- lapply(testGORes, grab_noise)
go_noise <- do.call(rbind, go_noise)
go_noise$class <- factor(go_noise$class, levels=c("low", "med", "hi"), ordered=TRUE)
ggplot(go_noise, aes(x = frac, y = diff)) + geom_point() + facet_grid(. ~ class, scales="free_x")

grab_noiseDiff <- function(x){
  outRes <- x$clean[, c("diff", "class", "frac")]
  outRes$diff <- x$noise$diff - x$clean$diff
  outRes
}
go_diff <- lapply(testGORes, grab_noiseDiff)
go_diff <- do.call(rbind, go_diff)
go_diff$class <- factor(go_diff$class, levels=c("low", "med", "hi"), ordered=TRUE)
ggplot(go_diff, aes(x = frac, y = diff)) + geom_point() + facet_grid(. ~ class, scales="free_x")
```

What if we aggregate things into bins first, based on their class and fraction?

```{r aggregate}
go_diff$frac10 <- round(go_diff$frac * 10) / 10
ggplot(go_diff, aes(x = frac10, y = diff, fill = class)) + geom_violin(alpha=0.5) 

go_noNoise$frac10 <- round(go_diff$frac)
```





## Expectations

Based on the above results, what I expect we will see if we do a programmatic search over the space is that there is a dependence on both the fraction of DE genes that are noisy, and the fraction of noisy genes that are shared (which really amounts to the same thing, but is a subtle point). 

# To Do:

* Run both the **noNoise** and **noise** 100 times with different sets of GO terms and make sure that this holds.
* Vary the fraction of noise genes, and also vary the fraction that is common, and find a way to quantify the effect.
