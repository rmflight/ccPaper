<!--
  %\VignetteEngine{knitr}
  %\VignetteIndexEntry{hypothetical example}
  %\VignetteDepends{categoryComparePaperRev, ggplot2, ALL, GO.db, hgu95av.db, hgu133plus2.db, limma}
-->
  
# Hypothetical Example
  
To demonstrate the utility of the general `categoryCompare` approach, we will construct an artificial data set based on the Gene Ontology. We will attempt to demonstrate that differences in the **set** or **list** based comparisons are also dependent on the number of items annotated to a particular term.

## Definitions

**Set** based: calculations performed independently on each *set* of features, and then the results are combined.

**List** based: calculations performed on the intersected *list* of two sets of features.

## GO Terms

```{r nGO}
nGO <- 20
```

We will make use of three sets of `r nGO` GO terms from *H. sapiens*. For each set, we want differing numbers of genes annotated to them.

### Num Annotations Dist

Let's first look at the distribution of number of genes annotated to the GO terms in **biological process**

```{r goAnnotations}
library(org.Hs.eg.db)
library(GO.db)
library(ccPaperRev)
hsGO <- as.list(org.Hs.egGO2ALLEGS)

goOntology <- Ontology(names(hsGO))
goBP <- names(goOntology)[goOntology == "BP"]
hsGO <- hsGO[goBP]
hsGO <- lapply(hsGO, unique)
universeGenes <- unique(unlist(hsGO))
```

```{r goCountDist}
library(ggplot2)
hsGO_count <- sapply(hsGO, length)
hsGO_count <- data.frame(count=hsGO_count)
ggplot(hsGO_count, aes(x=count)) + geom_bar(binwidth=10) + xlim(0, 2000) + ylim(0, 500)
```

### Set up groups

Based on the distribution in the previous figure, we will set up 3 different groups of GO terms, with a different number from each group:

  * low: 10-100, 50 terms
  * med: 250-500, 30 terms
  * hi: 500-1500, 20 terms
  
This gives us a total of 100 GO terms, with a good sample from each group. We will generate random samples that are defined by these limits, and use this set of GO terms going forward.

```{r defineGroupLimits}
grpLow <- c(10, 100)
grpMed <- c(250, 500)
grpHi <- c(500, 1500)
```

```{r sampleGroups}
set.seed(271113) # for reproducibility
nGO <- c(50, 30, 20)
names(nGO) <- c("low", "med", "hi")

GO_low <- limitedRandomSample(hsGO_count, grpLow, nGO["low"])
GO_med <- limitedRandomSample(hsGO_count, grpMed, nGO["med"])
GO_hi <- limitedRandomSample(hsGO_count, grpHi, nGO["hi"])

useGO <- c(GO_low, GO_med, GO_hi)
useGOSizeClass <- c(rep("low", nGO["low"]), rep("med", nGO["med"]), rep("hi", nGO["hi"]))
names(useGOSizeClass) <- useGO
```

### Examine Gene-GO Distribution for Real Data

Before we go and generate our samples, we should actually process some real experimental data and examine the fraction of annotated genes in the experiment compared to the total number of genes annotated. We will use the [`ALL`][http://master.bioconductor.org/packages/release/data/experiment/html/ALL.html] data set from `Bioconductor` and a [paired lung cancer dataset][http://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE18842] available from GEO (available as part of this package).

#### ALL

The `ALL` data set has two classes of tumor, **B** and **T**-cell lymphoblastoma. We will do a simple differential expression between the two cell types.

```{r deALL}
library(ALL)
library(limma)
data(ALL)

grpALL <- factor(strtrim(pData(ALL)$BT, 1))
designALL <- model.matrix(~0+grpALL)
colnames(designALL) <- c("B", "T")
fitALL <- lmFit(ALL, designALL)
contMatrixALL <- makeContrasts(BvT=B-T, levels=designALL)
fitALL2 <- contrasts.fit(fitALL, contMatrixALL)
fitALL2 <- eBayes(fitALL2)
deALL <- rownames(topTable(fitALL2, adjust="BH", p.value=0.05, number=Inf))
```

Now for all the GO terms that map to the probes in the `ALL` differentially expressed genes, how does the proportion of differentially expressed genes change as a function of the number of genes annotated to the GO term?

```{r goDistALL}
library(hgu95av2.db)
ALLgo <- as.list(hgu95av2GO2ALLPROBES)
ALL_sizeFrac <- trimGOFrac(ALLgo, deALL)
ggplot(ALL_sizeFrac, aes(x=size, y=frac)) + geom_point() + xlim(0, 1500)
```


#### Lung Cancer

The lung cancer data is a paired sample design from GEO.

```{r deLung}
data(lung)
sampleStat <- strsplit2(pData(lung)$title, " ")

notNP <- grep("^NP", sampleStat[,2], invert=T)
lung <- lung[, notNP]
sampleStat <- sampleStat[notNP,]

sampleID <- factor(sampleStat[,2])
cancerID <- factor(sampleStat[,1])

lungDesign <- model.matrix(~sampleID+cancerID)
fitLung <- lmFit(lung, lungDesign)
fitLung <- eBayes(fitLung)
deLung <- rownames(topTable(fitLung, coef="cancerIDTumor", number=2000, adjust.method="BY", p.value=0.00001))
```

```{r goDistLung}
library(hgu133plus2.db)
lung2go <- as.list(hgu133plus2GO2ALLPROBES)
lung_sizeFrac <- trimGOFrac(lung2go, deLung)
lung_sizeFrac$genelist <- "lung"
ggplot(lung_sizeFrac, aes(x=size, y=frac)) + geom_point() + xlim(0, 1500)
```



### Get Genes

Now, for all of these we need to generate **two** samples of genes from them to comprise our **differentially expressed** (DE) sets from the genome, representing two different expression experiments.

How do we select these two sets of genes?

* define the maximum number of diff genes for the set
* Randomly sort the GO terms
* For each GO term in turn (i.e. iterating over the GO terms):
  * take a random fraction of genes for that GO term (sampling from an exponentially decaying distribution of possibilites), adding the requisite number of genes
  * If all the genes for a GO term get taken, remove that GO term from future consideration
* Continue iterating through until the total number of genes is reached

What we expect from this is that in both datasets, the GO terms with lower numbers of genes annotated will have large fractions of their annotations present, while GO terms with more and more genes will have lower fractions, and there will be less overlap between the two datasets.

These expectations should be checked.

```{r generateSamples}
goList <- list(low=GO_low, med=GO_med, hi=GO_hi)
nGene <- 1000
sample1_org <- sampleTerms(useGO, hsGO, 1000, 4)[1:nGene]
sample2_org <- sampleTerms(useGO, hsGO, 1000, 4)[1:nGene]

#check our expectations
goFractions <- calcFraction(hsGO[useGO], list(sample1=sample1_org, sample2=sample2_org))
ggplot(goFractions, aes(x=size, y=frac, color=genelist)) + geom_point()
```

### Ccompare to experimental

Lets actually compare this to the distribution of fractions *vs* sizes from the experimental data sets. Because those used **all** the GO terms, we will redo them with **all** GO terms as well, not just those from our sample.

```{r compareFracs}
sampleGOFracs <- calcFraction(hsGO, list(sample1=sample1_org, sample2=sample2_org))
ALL_sizeFrac$genelist <- "all"
ALL_tmp <- rbind(ALL_sizeFrac, lung_sizeFrac, sampleGOFracs[,c("frac", "genelist", "size")])
ggplot(ALL_tmp, aes(x=size, y=frac)) + geom_point() + xlim(0, 1500) + facet_grid(genelist ~ .)
```


```{r cleanupData}
keepItems <- c("goFractions", "sample1_org", "sample2_org", "hsGO", "useGO", "useGOSizeClass", "GO_hi", "GO_low", "GO_med", "grpHi", "grpLow", "grpMed", "minGO", "nGO", "nGene", "universeGenes")
allItems <- ls()
delItems <- allItems[!(allItems %in% keepItems)]
rm(list=delItems)
```


### Do calculations

For each `geneList`, we will do the GO enrichment calculations, and then get the results. We also do the intersection of all the `geneList`'s, and do the calculations again.

```{r runCalcs}
samples_noNoise <- list(sample1 = sample1_org, sample2 = sample2_org)
go_noNoise <- hyperGOMultiEnrichment(samples_noNoise, universe=universeGenes)
```

Now get the p-values out (`-1 * log10(pvalue)`). For each of our test GO terms, we take the minimum p-value from the results of the **set** calculations, and also the values from the **list** calculations.

```{r noNoisePvalues}
noNoise_results <- pvaluesMultiEnrich(c("sample1", "sample2"), useGO, go_noNoise)

noNoise_pvalues <- pvalueDiffSig(noNoise_results$values, pCutoff=0.05, log=TRUE)
```

Finally, lets add in our values of the fraction, total genes, and the class (**low**, **med**, **hi**) so we can do some fancy plotting stuff with it.

```{r noNoiseAddInfo}
noNoise_pvalues$sizeClass <- useGOSizeClass
noNoise_pvalues$size <- goFractions[1:length(useGOSizeClass),4]
noNoise_pvalues$frac <- goFractions$frac[1:length(useGOSizeClass)]
```

Now we will plot the difference in log-p-values (where we have **set** - **list**), so that positive values imply that **set** had lower p-values than **list**, based on the *fraction* of genes annotated.

```{r noNoisePlotStuff}
noNoise_pvalues$sizeClass <- factor(noNoise_pvalues$sizeClass, levels=c("low", "med", "hi"), ordered=TRUE)
ggplot(noNoise_pvalues, aes(x=frac, y=diff, color=sigState)) + geom_point() + facet_grid(. ~ sizeClass, scales="free_x")
ggplot(noNoise_pvalues, aes(x=sizeClass, y=diff)) + geom_boxplot() + geom_point()
```

We can see that it appears in general that **set** has better p-values than **list**, especially in the *med* and *hi* groups. Also, both methods get pretty much the same GO terms as significant. 

How many of the GO terms have better p-values in **set** compared to **list**?

```{r noNoiseBetterPVals}
tapply(noNoise_pvalues$diff, noNoise_pvalues$sizeClass, function(x){sum(x > 0)})
```

What is the average difference among each group?

```{r noNoiseBetterMean}
tapply(noNoise_pvalues$diff, noNoise_pvalues$sizeClass, mean)
```

So ideally, the mean of the full set of differences, combined with how many pass in each case, should adequately quantify how well each of the methods is doing. 

## Noise

In addition to the genes that are annotated to the GO terms of interest, we will also add in genes that have no relation to the GO terms under consideration, these would be considered **noise** genes. To make the model simple, we will have the **same** genes as noise in **both** samples.

```{r noiseGenes}
nNoise <- 500
noiseGenes <- possibleNoise(hsGO, useGO)
noiseGenes <- sample(noiseGenes, nNoise)

# check that we did this right, the fraction should not change after adding noise genes
sample1 <- c(sample1_org, noiseGenes)
sample2 <- c(sample2_org, noiseGenes)

samplesNoise <- list(sample1=sample1, sample2=sample2)

goFracNoise <- calcFraction(hsGO[useGO], samplesNoise)
plot(goFracNoise$frac, goFractions$frac)
```


```{r noisyEnrichment}
go_noise <- hyperGOMultiEnrichment(samplesNoise, universeGenes)
```

```{r noisePvalues}
noise_results <- pvaluesMultiEnrich(c("sample1", "sample2"), useGO, go_noise)

noise_pvalues <- pvalueDiffSig(noise_results$values, pCutoff=0.05, log=TRUE)

noise_pvalues$sizeClass <- useGOSizeClass
noise_pvalues$size <- goFracNoise[1:length(useGOSizeClass),4]
noise_pvalues$frac <- goFracNoise$frac[1:length(useGOSizeClass)]
```

```{r plotSummarizeNoise}
noise_pvalues$sizeClass <- factor(noise_pvalues$sizeClass, c("low", "med", "hi"), ordered=TRUE)
ggplot(noise_pvalues, aes(x=frac, y=diff, color=sigState)) + geom_point() + facet_grid(. ~ sizeClass, scales="free_x")
```

```{r summarizeCountsNoise}
tapply(noise_pvalues$diff, noise_pvalues$sizeClass, function(x){sum(x > 0)})
tapply(noise_pvalues$diff, noise_pvalues$sizeClass, mean)
```

Although using gene lists that were perfect (i.e. no noise) everything in the **list** method was pretty much still significant, on average **sets** gave much better p-values. However, as we add noise to the system in the form of genes that are not annotated to our test GO terms, more terms are significant only in the **sets** method (i.e. show up in **both** sets). 

### Difference of Differences

Is there any **difference** in the *difference of p-values* between **noise** vs **noNoise** (comparing **set** vs **list**)?

```{r diffDiffs}
diff_pvalues <- noise_pvalues
diff_pvalues$diff <- noise_pvalues$diff - noNoise_pvalues$diff
ggplot(diff_pvalues, aes(x=frac, y=diff)) + geom_point() + facet_grid(. ~ sizeClass, scales="free_x")
tapply(diff_pvalues$diff, diff_pvalues$sizeClass, mean)
```

From this plot, it appears that not only do the **set** values return lower p-values, but return lower p-values when noise is added overall.


## Check Consistency

To make sure that the results are consistent, we will do several iterations of the above calculations.

* For this set of GO terms, do the above calculations 100 times
* Generate 100 different sets of GO terms, and run calculations again.

### Gene Sample Level Consistency

```{r geneSamples, eval=FALSE}
nTimes <- 100
nGene <- 1000

testSamples <- lapply(seq(1, nTimes), function(x){
  list(s1 = sampleTerms(useGO, hsGO, 1000, 4)[1:nGene],
       s2 = sampleTerms(useGO, hsGO, 1000, 4)[1:nGene],
       noise = sample(noiseGenes, nNoise))
})

save(useGO, testSamples, universeGenes, useGOSizeClass, file="inst/data/100GeneSamples.RData")
```

```{r runSamples, eval=FALSE}
library(snowfall)
# load("inst/data/100GeneSamples.RData")
testFun <- function(x){
  nnList <- x[c("s1", "s2")]
  nnRes <- hyperGOMultiEnrichment(nnList, universe=universeGenes)
  nn_res <- pvaluesMultiEnrich(c("s1", "s2"), useGO, nnRes)
  nnP <- pvalueDiffSig(nn_res$values, pCutoff=0.05, log=TRUE)
  nnP$class <- useGOSizeClass
  
  noiList <- list(s1 = c(x$s1, x$noise), s2 = c(x$s2, x$noise))
  noiRes <- hyperGOMultiEnrichment(noiList, universe=universeGenes)
  noi_res <- pvaluesMultiEnrich(c("s1", "s2"), useGO, noiRes)
  noiP <- pvalueDiffSig(noi_res$values, pCutoff=0.05, log=TRUE)
  noiP$class <- useGOSizeClass

  return(list(clean = nnP, noise = noiP))
}
sfInit(parallel=TRUE, cpus=10)
sfExport("useGOSizeClass", "universeGenes", "useGO")
sfLibrary(ccPaperRev)
sfLibrary(GO.db)
sfLibrary(org.Hs.eg.db)
testRes <- sfLapply(testSamples, testFun)
sfStop()
save(testRes, file="inst/data/100GeneResults.RData")
```

### Errors from 100 Samples of the initial set of GO terms

For each of the GO terms, we want to calculate the mean, standard deviation, and then a 95% confidence interval to represent graphically.

```{r noNoiseStats}
useDir <- "/mlab/data/rmflight/Documents/projects/work/categoryComparePaperRev"
load(file.path(useDir, "inst/data/100GeneResults.RData"))
cleanRes <- lapply(testRes, function(x){x$clean})
testStats_clean <- sameGOStats(cleanRes)
testStats_clean$class <- useGOSizeClass
testStats_clean$frac <- goFractions$frac[1:length(useGOSizeClass)]
testStats_clean$class <- factor(testStats_clean$class, levels=c("low", "med", "hi"), ordered=TRUE)
ggplot(testStats_clean, aes(x=frac, y=mean, ymax=max, ymin=min)) + geom_point() + geom_errorbar() + facet_grid(. ~ class, scales="free_x")
```

```{r noiseStats}
noiseRes <- lapply(testRes, function(x){x$noise})
testStats_noise <- sameGOStats(noiseRes)
testStats_noise$class <- useGOSizeClass
testStats_noise$frac <- goFracNoise$frac[1:length(useGOSizeClass)]
testStats_noise$class <- factor(testStats_noise$class, levels=c("low", "med", "hi"), ordered=TRUE)
ggplot(testStats_noise, aes(x=frac, y=mean, ymax=max, ymin=min)) + geom_point() + geom_errorbar() + facet_grid(. ~ class, scales="free_x")
```

These show that if there is a difference in the p-values from **set** and **list**, they are real.

What about differences between noise and clean?

```{r 100GeneNoiseClean}
noiseCleanDiff <- diffGOStats(testRes)
noiseCleanDiff$class <- useGOSizeClass
noiseCleanDiff$frac <- goFracNoise$frac[1:length(useGOSizeClass)]
noiseCleanDiff$class <- factor(noiseCleanDiff$class, levels=c("low", "med", "hi"), ordered=TRUE)
ggplot(noiseCleanDiff, aes(x=frac, y=mean, ymax=max, ymin=min)) + geom_point() + geom_errorbar() + facet_grid(. ~ class, scales="free_x")
```

Here we see that the noisy case also tends to generate higher differences in p-values between **set** and **list** than the clean case.

**Caveats**: Currently the *fraction* of genes annotated to GO terms is assumed to be the same for each sample. This may not actually be the case, and ideally this should be repeated with independent fraction estimates for each sampling.


## GO Samples

OK, the error bars are not too bad. How about sampling multiple sets of GO terms??


```{r genSamples, eval=FALSE}
goLimits <- list(low = c(10, 100), med = c(250, 500), hi = c(500, 1500))

nSample <- 100

sfInit(parallel=TRUE, cpus=10)
sfLibrary(ccPaperRev)
sfExport("hsGO", "nGO", "goLimits")

testGOSample <- sfLapply(seq(1, nSample), function(x){
  t1 <- goSample(hsGO, nGO, goLimits, nSample=2, nGene=1000, nNoise=500)
  return(t1)
})

sfStop()
save(testGOSample, file="inst/data/100GOSamples.RData")
```

Running those samples:

```{r runGOSamples, eval=FALSE}
runGOSamples <- function(x){
  cleanSample <- x$geneSample
  cleanRes <- hyperGOMultiEnrichment(cleanSample, universe=universeGenes)
  
  cleanP <- pvaluesMultiEnrich(names(cleanSample), x$goData$id, cleanRes)
  cleanP_dif <- pvalueDiffSig(cleanP$values, pCutoff=0.05, log=TRUE)
  cleanP_dif <- cbind(cleanP_dif, x$goData)
  
  noiseSample <- lapply(names(cleanSample), function(inSample){
    c(x$geneSample[[inSample]], x$noiseSample[[inSample]])
  })
  names(noiseSample) <- names(cleanSample)
  noiseRes <- hyperGOMultiEnrichment(noiseSample, universe=universeGenes)
  noiseP <- pvaluesMultiEnrich(names(cleanSample), x$goData$id, noiseRes)
  noiseP_dif <- pvalueDiffSig(noiseP$values, pCutoff=0.05, log=TRUE)
  noiseP_dif <- cbind(noiseP_dif, x$goData)
  return(list(clean = cleanP_dif, noise = noiseP_dif))
}

library(snowfall)
sfInit(parallel=TRUE, cpus=10)
sfLibrary(ccPaperRev)
sfLibrary(org.Hs.eg.db)
sfLibrary(GO.db)
sfExport("universeGenes")

testGORes <- sfLapply(testGOSample, runGOSamples)
sfStop()
save(testGORes, file="inst/data/100GOResults.RData")
```

```{r lookDiffs}
load(file.path(useDir, "inst/data/100GOResults.RData"))

grab_noNoise <- function(x){
  x$clean[,c("diff", "class", "frac")]
}

go_noNoise <- lapply(testGORes, grab_noNoise)
go_noNoise <- do.call(rbind, go_noNoise)
go_noNoise$class <- factor(go_noNoise$class, levels=c("low", "med", "hi"), ordered=TRUE)
ggplot(go_noNoise, aes(x = frac, y = diff)) + geom_point() + facet_grid(. ~ class, scales="free_x")

grab_noise <- function(x){
  x$noise[, c("diff", "class", "frac")]
}
go_noise <- lapply(testGORes, grab_noise)
go_noise <- do.call(rbind, go_noise)
go_noise$class <- factor(go_noise$class, levels=c("low", "med", "hi"), ordered=TRUE)
ggplot(go_noise, aes(x = frac, y = diff)) + geom_point() + facet_grid(. ~ class, scales="free_x")

grab_noiseDiff <- function(x){
  outRes <- x$clean[, c("diff", "class", "frac")]
  outRes$diff <- x$noise$diff - x$clean$diff
  outRes
}
go_diff <- lapply(testGORes, grab_noiseDiff)
go_diff <- do.call(rbind, go_diff)
go_diff$class <- factor(go_diff$class, levels=c("low", "med", "hi"), ordered=TRUE)
ggplot(go_diff, aes(x = frac, y = diff)) + geom_point() + facet_grid(. ~ class, scales="free_x")
ggplot(go_diff, aes(x = frac, y = diff, fill=class)) + geom_boxplot(position="identity", alpha=0.4)
```


How about we compare the distribution of noise and no-noise using violin plots?

```{r compNoiseNoNoise}
go_noise$noise <- "noise"
go_noNoise$noise <- "none"

go_all <- rbind(go_noise, go_noNoise)
rownames(go_all) <- NULL
ggplot(go_all, aes(x = frac, y = diff, fill = noise)) + geom_violin(trim=TRUE, alpha=0.5, position="identity") + facet_grid(. ~ class, scales="free_x")
```


What if we aggregate things into bins first, based on their class and fraction?

```{r aggregate}
go_diff$frac10 <- round(go_diff$frac * 10) / 10
ggplot(go_diff, aes(x = factor(frac10), y = diff)) + geom_boxplot() + facet_grid(. ~ class, scales="free_x") 

probPoint <- is.infinite(go_diff$diff) | is.na(go_diff$diff) | is.nan(go_diff$diff)
go_diff <- go_diff[!probPoint, ]
ggplot(go_diff, aes(x=frac, y=diff)) + stat_smooth() + facet_grid(. ~ class, scales="free_x")
```

Although the improvement of noise over clean data dips below 0 at medium fractions, it does tend to improve rather significantly as the fraction of genes annotated to a GO term increases.


## As a function of noisy and shared noise genes

For a given set of genes and GO terms, lets now keep adding more and more noise genes, and for the set amount of noise genes, go from 0% to 100% shared noise genes. And then see how things change. For this, we are going to use our initial set of GO terms (`useGO`), and a single original set of genes, simply sampling noise genes as we go along. Note that in this case **noise** genes are defined as genes that are not annotated to any of the GO terms that the DE genes are annotated to.

As in the previous examples, we will generate the samples first, and then run the calculations on them. This is because it is easier to test sample generation and enrichment separately.

```{r sweepNoise}
noiseGenes <- possibleNoise(hsGO, useGO)
sizeNoise <- seq(0, 1000, 10)
fracShared <- seq(0, 1, 0.01)
noiseSamples <- sweepNoiseSample(noiseGenes, nSamples=2, sizeNoise, fracShared)

nGene <- 1000
cleanSample <- list(s1 = sampleTerms(useGO, hsGO, nGene, 4)[1:nGene],
                    s2 = sampleTerms(useGO, hsGO, nGene, 4)[1:nGene])

save(noiseSamples, cleanSample, sizeNoise, fracShared, universeGenes, useGO, useGOSizeClass, file=file.path(useDir, 'inst/data/noiseSamples.RData'))
```

```{r runSweptNoise}
useDir <- '/mlab/data/rmflight/Documents/projects/work/categoryComparePaperRev/'
load(file.path(useDir, 'inst/data/noiseSamples.RData'))

useNoise <- unlist(noiseSamples, recursive=FALSE)
sizeNoiseAll <- rep(sizeNoise, each=length(fracShared))
fracSharedAll <- rep(fracShared, length(sizeNoise))

runSweepNoise <- function(noiseGenes){
  inNoise <- lapply(seq(1, length(cleanSample)), function(x){
    c(cleanSample[[x]], noiseGenes[[x]])
  })
  names(inNoise) <- names(cleanSample)
  
  noiseRes <- hyperGOMultiEnrichment(inNoise, universe=universeGenes)
  noiseP <- pvaluesMultiEnrich(names(inNoise), useGO, noiseRes)
  noisePComp <- pvalueDiffSig(noiseP$values, pCutoff=0.05, log=TRUE)
  noisePComp$class <- useGOSizeClass
  return(noisePComp)
}

library(snowfall)
sfInit(parallel=TRUE, cpus=10)
sfLibrary(ccPaperRev)
sfLibrary(org.Hs.eg.db)
sfLibrary(GO.db)
sfExport("universeGenes", "useGO", "useGOSizeClass", "cleanSample")
noiseSweepRes <- sfLapply(useNoise, runSweepNoise)
sfStop()
save(noiseSweepRes, file.path(useDir, "inst/data/noiseSweepRes.RData"))
```



# GSEA

Another way to do the analysis is using a Gene Set Enrichment Analysis, or GSEA. In contrast to over-representation analysis, where we count if a group is more highly represented in a group *vs* the background; GSEA tests if a **set** of genes are more highly ranked than random sets of genes. 

For a hypothetical example, we are going to use the `geneSetTest` from `limma`, because it allows us to test on a set of gene statistics themselves.

## Data set up

The sets will be our same GO terms, and we will change the proportion of genes from each GO term that are enhanced above a base value. All genes will be assigned a value from a uniform distribution with a value of 0.5. For each GO term set, some genes will be selected (with an exponential decaying probability for more genes), and assigned p-values from a uniform distribution with a value of 0.01.

For the **list** version, the p-values of genes will be combined using **Fishers** method, see the function `fishersMethod` provided in this package.

## Generate Data

We will use the t-values that `limma` has generated for the ALL data set, and just sample from those.

```{r generateSampleRanks}
tALL <- topTable(fitALL2, number=Inf)
tALL <- tALL$t[(tALL$t < 10) & (tALL$t > -10)]
tValues <- sample(tALL, length(universeGenes), replace=TRUE)

gseaSamples <- list(s1 = sampleTerms(useGO, hsGO, 1000, 4),
                    s2 = sampleTerms(useGO, hsGO, 1000, 4))

gseaGOFracS1 <- calcFraction(hsGO[useGO], list(s1=gseaSamples[[1]]))

gseaTValues <- sampletValueGenGSEA(gseaSamples, universeGenes, tValues)
```

Check that we did what we thought. If done right, all of the **sample** genes should be on one side of the a histogram.

```{r checkValues}
tmpDat <- data.frame(x=gseaTValues[[1]], type="all", stringsAsFactors=FALSE)
tmpDat$type[(universeGenes %in% gseaSamples[[1]])] <- "sample"
ggplot(tmpDat, aes(x=x, fill=type)) + geom_histogram(binwidth=0.1, position="identity")

tmpComb <- data.frame(x=gseaTValues[["comb"]], type="all", stringsAsFactors=FALSE)
tmpComb$type[(universeGenes %in% gseaSamples[[1]])] <- "sample"
ggplot(tmpComb, aes(x=x, fill=type)) + geom_histogram(binwidth=0.1, position="identity")
```

Now lets actually do some calculations.

```{runSomeGSEA}
go2index <- symbols2indices(hsGO[useGO], universeGenes)
gseaSetResults <- lapply(gseaTValues, function(x){
  mmGeneSetTest(go2index, x)
})
```

And figure out what is doing better.

```{r gseaBetter}
cleanDiff <- gseaDiffs(gseaSetResults)
cleanDiff$sizeClass <- useGOSizeClass
cleanDiff$sizeClass <- factor(cleanDiff$sizeClass, c("low", "med", "hi"), ordered=TRUE)
cleanDiff$frac <- gseaGOFracS1$frac

ggplot(cleanDiff, aes(x=frac, y=diff)) + geom_point() + facet_grid(. ~ sizeClass)
```

So this appears to be a different trend than for the hypergeometric case, in that a **meta** sample (achieved by averaging the t-statistics) actually does no worse, and in many cases much better than the worst p-value. This effect is less-pronounced as the number of genes in a class become larger, and as the fraction covered increases.

So what happens if we add some noisy genes into the top 1000? Stuff that isn't annotated at all to the GO terms of interest?

```{r gseaNoise}
nNoise <- 2000
noiseGenes <- possibleNoise(hsGO, useGO)
noiseGenes <- sample(noiseGenes, nNoise)

gseaNoise <- list(s1=c(gseaSamples[["s1"]], noiseGenes),
                  s2=c(gseaSamples[["s2"]], noiseGenes))

gseaTValues_noise <- sampletValueGenGSEA(gseaNoise, universeGenes, tValues)

tmpDat <- data.frame(x=gseaTValues_noise[[1]], type="all", stringsAsFactors=FALSE)
tmpDat$type[(universeGenes %in% gseaSamples[[1]])] <- "sample"
ggplot(tmpDat, aes(x=x, fill=type)) + geom_histogram(binwidth=0.1, position="identity", alpha=0.75)
```

```{r runGSEANoise}
gseaSetResults_noise <- lapply(gseaTValues_noise, function(x){
  mmGeneSetTest(go2index, x)
})
```

```{r gseaBetter}
noiseDiff <- gseaDiffs(gseaSetResults_noise)
noiseDiff$sizeClass <- useGOSizeClass
noiseDiff$sizeClass <- factor(noiseDiff$sizeClass, c("low", "med", "hi"), ordered=TRUE)
noiseDiff$frac <- gseaGOFracS1$frac

ggplot(noiseDiff, aes(x=frac, y=diff)) + geom_point() + facet_grid(. ~ sizeClass)
```